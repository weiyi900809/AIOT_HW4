"""
MNIST æ‰‹å¯«æ•¸å­—è¾¨è­˜ç¥ç¶“ç¶²è·¯ - æ“´å±•ç‰ˆæœ¬
Demo01 - è¨­è¨ˆä½ çš„ç¥ç¶“ç¶²è·¯ (å«å‰è™•ç†ã€æŒ‡æ¨™åˆ†æã€Streamlit UI)

é€™å€‹è…³æœ¬å»ºç«‹ä¸€å€‹ç¥ç¶“ç¶²è·¯æ¨¡å‹ä¾†è¾¨è­˜ MNIST æ‰‹å¯«æ•¸å­—è³‡æ–™é›†ï¼ŒåŒ…å«ï¼š
  - è±å¯Œçš„æ•¸æ“šå‰è™•ç†æ­¥é©Ÿï¼ˆæ­£è¦åŒ–ã€æ¨™æº–åŒ–ã€æ•¸æ“šå¢å¼·ã€æª¢é©—åˆ†å‰²ï¼‰
  - è©³ç´°çš„è¨“ç·´æŒ‡æ¨™å’Œæ€§èƒ½åˆ†æï¼ˆæ··æ·†çŸ©é™£ã€åˆ†é¡å ±å‘Šã€é€é¡ç²¾åº¦ï¼‰
  - å®Œæ•´çš„ Streamlit äº’å‹•å¼æ‡‰ç”¨ï¼ˆå«å¯¦æ™‚ç¹ªåœ–è¾¨è­˜å’Œå¯è¦–åŒ–åˆ†æï¼‰
"""

import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.callbacks import EarlyStopping
import streamlit as st
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
import seaborn as sns
import pickle
import os
from datetime import datetime

# ===== è¶…åƒæ•¸è¨­å®š =====
N1 = 20  # ç¬¬ä¸€éš±è—å±¤ç¥ç¶“å…ƒæ•¸
N2 = 20  # ç¬¬äºŒéš±è—å±¤ç¥ç¶“å…ƒæ•¸
N3 = 20  # ç¬¬ä¸‰éš±è—å±¤ç¥ç¶“å…ƒæ•¸
BATCH_SIZE = 100
EPOCHS = 10
LEARNING_RATE = 0.087
VALIDATION_SPLIT = 0.2


# ===== è³‡æ–™å‰è™•ç†å‡½å¼åº« =====
class MNISTPreprocessor:
    """MNIST æ•¸æ“šå‰è™•ç†é¡åˆ¥"""
    
    @staticmethod
    def load_data():
        """åŠ è¼‰åŸå§‹ MNIST æ•¸æ“š"""
        print("ğŸ“¥ æ­£åœ¨åŠ è¼‰ MNIST æ•¸æ“šé›†...")
        (x_train, y_train), (x_test, y_test) = mnist.load_data()
        print(f"   è¨“ç·´è³‡æ–™: {x_train.shape}, æ¸¬è©¦è³‡æ–™: {x_test.shape}")
        return (x_train, y_train), (x_test, y_test)
    
    @staticmethod
    def normalize(x):
        """
        æ­£è¦åŒ–ï¼šå°‡åƒç´ å€¼ç¸®æ”¾è‡³ [0, 1]
        å…¬å¼: x_normalized = x / 255
        """
        return x / 255.0
    
    @staticmethod
    def standardize(x):
        """
        æ¨™æº–åŒ–ï¼šå°‡æ•¸æ“šè½‰ç‚º 0 å‡å€¼å’Œå–®ä½æ–¹å·®
        å…¬å¼: x_std = (x - mean) / std
        """
        mean = np.mean(x)
        std = np.std(x)
        return (x - mean) / (std + 1e-8), mean, std
    
    @staticmethod
    def flatten(x):
        """å°‡ 2D åœ–åƒ (28, 28) è½‰ç‚º 1D å‘é‡ (784,)"""
        n_samples = x.shape[0]
        return x.reshape(n_samples, -1)
    
    @staticmethod
    def one_hot_encode(y, num_classes=10):
        """è½‰æ›æ¨™ç±¤ç‚º one-hot ç·¨ç¢¼"""
        return to_categorical(y, num_classes)
    
    @staticmethod
    def data_augmentation(x, intensity=0.1):
        """
        æ•¸æ“šå¢å¼·ï¼šæ·»åŠ å°é‡é«˜æ–¯å™ªè²ä»¥å¢åŠ æ¨¡å‹é­¯æ£’æ€§
        """
        noise = np.random.normal(0, intensity, x.shape)
        x_augmented = np.clip(x + noise, 0, 1)
        return x_augmented
    
    @staticmethod
    def preprocess_pipeline(x_train, y_train, x_test, y_test):
        """å®Œæ•´çš„å‰è™•ç†æµç¨‹"""
        print("\nğŸ”§ é–‹å§‹å‰è™•ç†...")
        
        # æ­¥é©Ÿ 1: æ­£è¦åŒ–
        print("  [1/6] æ­£è¦åŒ–åƒç´ å€¼ (0-1)...")
        x_train_norm = MNISTPreprocessor.normalize(x_train)
        x_test_norm = MNISTPreprocessor.normalize(x_test)
        
        # æ­¥é©Ÿ 2: æ”¤å¹³
        print("  [2/6] æ”¤å¹³åœ–åƒ (28x28 â†’ 784)...")
        x_train_flat = MNISTPreprocessor.flatten(x_train_norm)
        x_test_flat = MNISTPreprocessor.flatten(x_test_norm)
        
        # æ­¥é©Ÿ 3: æ¨™æº–åŒ–
        print("  [3/6] æ¨™æº–åŒ–ç‰¹å¾µ...")
        x_train_std, train_mean, train_std = MNISTPreprocessor.standardize(x_train_flat)
        x_test_std = (x_test_flat - train_mean) / (train_std + 1e-8)
        
        # æ­¥é©Ÿ 4: æ•¸æ“šå¢å¼·
        print("  [4/6] æ‡‰ç”¨æ•¸æ“šå¢å¼·...")
        x_train_aug = MNISTPreprocessor.data_augmentation(x_train_std, intensity=0.05)
        
        # æ­¥é©Ÿ 5: One-hot ç·¨ç¢¼
        print("  [5/6] ç·¨ç¢¼æ¨™ç±¤...")
        y_train_enc = MNISTPreprocessor.one_hot_encode(y_train)
        y_test_enc = MNISTPreprocessor.one_hot_encode(y_test)
        
        # æ­¥é©Ÿ 6: çµ±è¨ˆè³‡è¨Š
        print("  [6/6] ç”Ÿæˆçµ±è¨ˆè³‡è¨Š...")
        stats = {
            'train_shape': x_train_aug.shape,
            'test_shape': x_test_flat.shape,
            'train_mean': np.mean(x_train_aug),
            'train_std': np.std(x_train_aug),
            'test_mean': np.mean(x_test_std),
            'test_std': np.std(x_test_std),
            'train_min': np.min(x_train_aug),
            'train_max': np.max(x_train_aug),
        }
        
        print("âœ… å‰è™•ç†å®Œæˆï¼\n")
        return x_train_aug, y_train_enc, x_test_std, y_test_enc, stats


# ===== æ¨¡å‹é¡åˆ¥ =====
class MNISTNeuralNetwork:
    """MNIST ç¥ç¶“ç¶²è·¯æ¨¡å‹"""
    
    def __init__(self, n1=20, n2=20, n3=20, learning_rate=0.087):
        self.n1 = n1
        self.n2 = n2
        self.n3 = n3
        self.learning_rate = learning_rate
        self.model = self._build_model()
        self.history = None
    
    def _build_model(self):
        """å»ºç«‹ç¥ç¶“ç¶²è·¯æ¨¡å‹"""
        model = Sequential()
        model.add(Dense(self.n1, input_dim=784, activation='relu', name='hidden1'))
        model.add(Dense(self.n2, activation='relu', name='hidden2'))
        model.add(Dense(self.n3, activation='relu', name='hidden3'))
        model.add(Dense(10, activation='softmax', name='output'))
        
        model.compile(
            loss='mse',
            optimizer=SGD(learning_rate=self.learning_rate),
            metrics=['accuracy']
        )
        return model
    
    def train(self, x_train, y_train, batch_size=100, epochs=10, validation_split=0.2):
        """è¨“ç·´æ¨¡å‹"""
        early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)
        
        self.history = self.model.fit(
            x_train, y_train,
            batch_size=batch_size,
            epochs=epochs,
            validation_split=validation_split,
            callbacks=[early_stop],
            verbose=1
        )
        return self.history
    
    def evaluate(self, x_test, y_test):
        """è©•ä¼°æ¨¡å‹"""
        loss, acc = self.model.evaluate(x_test, y_test, verbose=0)
        return loss, acc
    
    def predict(self, x):
        """é æ¸¬"""
        return self.model.predict(x, verbose=0)


# ===== æŒ‡æ¨™è¨ˆç®—å‡½å¼ =====
def calculate_metrics(y_true, y_pred, class_names=None):
    """è¨ˆç®—è©³ç´°çš„åˆ†é¡æŒ‡æ¨™"""
    if class_names is None:
        class_names = [str(i) for i in range(10)]
    
    # è½‰æ›ç‚ºé¡åˆ¥æ¨™ç±¤
    y_true_labels = np.argmax(y_true, axis=1)
    y_pred_labels = np.argmax(y_pred, axis=1)
    
    # è¨ˆç®—å„ç¨®æŒ‡æ¨™
    accuracy = accuracy_score(y_true_labels, y_pred_labels)
    conf_matrix = confusion_matrix(y_true_labels, y_pred_labels)
    class_report = classification_report(y_true_labels, y_pred_labels, target_names=class_names, output_dict=True)
    
    return {
        'accuracy': accuracy,
        'confusion_matrix': conf_matrix,
        'classification_report': class_report,
        'y_pred_labels': y_pred_labels,
        'y_true_labels': y_true_labels
    }


# ===== Streamlit UI =====
def main():
    st.set_page_config(page_title="MNIST æ‰‹å¯«è¾¨è­˜ç³»çµ±", layout="wide", initial_sidebar_state="expanded")
    
    # æ¨™é¡Œå’Œèªªæ˜
    st.title("ğŸ§  MNIST æ‰‹å¯«æ•¸å­—è¾¨è­˜ç³»çµ±")
    st.markdown("**æ“´å±•ç‰ˆæœ¬** - åŒ…å«è±å¯Œçš„å‰è™•ç†ã€æŒ‡æ¨™åˆ†æå’Œäº’å‹•å¼é æ¸¬")
    
    # å´é‚Šæ¬„ - åƒæ•¸è¨­å®š
    st.sidebar.header("âš™ï¸ æ¨¡å‹é…ç½®")
    n1 = st.sidebar.slider("éš±è—å±¤ 1 ç¥ç¶“å…ƒæ•¸", 10, 100, N1)
    n2 = st.sidebar.slider("éš±è—å±¤ 2 ç¥ç¶“å…ƒæ•¸", 10, 100, N2)
    n3 = st.sidebar.slider("éš±è—å±¤ 3 ç¥ç¶“å…ƒæ•¸", 10, 100, N3)
    lr = st.sidebar.slider("å­¸ç¿’ç‡", 0.001, 0.1, LEARNING_RATE, step=0.001)
    epochs = st.sidebar.slider("è¨“ç·´é€±æœŸ", 5, 20, EPOCHS)
    
    st.sidebar.header("ğŸ“Š æª¢è¦–é¸é …")
    show_preprocessing = st.sidebar.checkbox("é¡¯ç¤ºå‰è™•ç†è©³æƒ…", value=True)
    show_training = st.sidebar.checkbox("é¡¯ç¤ºè¨“ç·´éç¨‹", value=True)
    show_metrics = st.sidebar.checkbox("é¡¯ç¤ºè©³ç´°æŒ‡æ¨™", value=True)
    show_prediction = st.sidebar.checkbox("å•Ÿç”¨å³æ™‚é æ¸¬", value=True)
    
    # ä¸»è¦æ¨™ç±¤
    tab1, tab2, tab3, tab4, tab5 = st.tabs(
        ["ğŸ“¥ æ•¸æ“šåŠ è¼‰", "ğŸ”§ å‰è™•ç†åˆ†æ", "ğŸ“ˆ è¨“ç·´éç¨‹", "ğŸ“Š æ¨¡å‹è©•ä¼°", "ğŸ¨ å³æ™‚é æ¸¬"]
    )
    
    # ===== æ¨™ç±¤ 1: æ•¸æ“šåŠ è¼‰ =====
    with tab1:
        st.header("æ•¸æ“šåŠ è¼‰")
        if st.button("ğŸš€ åŠ è¼‰ MNIST æ•¸æ“šé›†", key="load_data"):
            with st.spinner("æ­£åœ¨åŠ è¼‰æ•¸æ“š..."):
                (x_train, y_train), (x_test, y_test) = MNISTPreprocessor.load_data()
                st.session_state.x_train_raw = x_train
                st.session_state.y_train_raw = y_train
                st.session_state.x_test_raw = x_test
                st.session_state.y_test_raw = y_test
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("è¨“ç·´æ¨£æœ¬æ•¸", len(x_train))
                st.metric("åœ–åƒå°ºå¯¸", "28 Ã— 28")
            with col2:
                st.metric("æ¸¬è©¦æ¨£æœ¬æ•¸", len(x_test))
                st.metric("é¡åˆ¥æ•¸", 10)
        
        # é¡¯ç¤ºæ¨£æœ¬åœ–åƒ
        if 'x_train_raw' in st.session_state:
            st.subheader("æ¨£æœ¬åœ–åƒå±•ç¤º")
            sample_idx = st.slider("é¸æ“‡æ¨£æœ¬ç´¢å¼•", 0, 59999, 0)
            
            col1, col2 = st.columns(2)
            with col1:
                fig, ax = plt.subplots(figsize=(5, 5))
                ax.imshow(st.session_state.x_train_raw[sample_idx], cmap='Greys')
                ax.set_title(f"è¨“ç·´æ¨£æœ¬ #{sample_idx}\næ¨™ç±¤: {st.session_state.y_train_raw[sample_idx]}", fontsize=14)
                ax.axis('off')
                st.pyplot(fig)
            
            with col2:
                st.write("**åƒç´ å€¼çµ±è¨ˆ:**")
                img = st.session_state.x_train_raw[sample_idx]
                st.info(f"""
                æœ€å°å€¼: {np.min(img)} | æœ€å¤§å€¼: {np.max(img)}
                å¹³å‡å€¼: {np.mean(img):.2f} | æ¨™æº–å·®: {np.std(img):.2f}
                åƒç´ å€‹æ•¸: {img.size}
                """)
    
    # ===== æ¨™ç±¤ 2: å‰è™•ç†åˆ†æ =====
    with tab2:
        st.header("å‰è™•ç†æµç¨‹åˆ†æ")
        if 'x_train_raw' not in st.session_state:
            st.warning("âš ï¸ è«‹å…ˆåœ¨'æ•¸æ“šåŠ è¼‰'æ¨™ç±¤åŠ è¼‰æ•¸æ“š")
        else:
            if st.button("ğŸ”§ åŸ·è¡Œå‰è™•ç†", key="preprocess"):
                with st.spinner("å‰è™•ç†ä¸­..."):
                    x_train_processed, y_train_enc, x_test_processed, y_test_enc, stats = \
                        MNISTPreprocessor.preprocess_pipeline(
                            st.session_state.x_train_raw,
                            st.session_state.y_train_raw,
                            st.session_state.x_test_raw,
                            st.session_state.y_test_raw
                        )
                    st.session_state.x_train = x_train_processed
                    st.session_state.y_train = y_train_enc
                    st.session_state.x_test = x_test_processed
                    st.session_state.y_test = y_test_enc
                    st.session_state.stats = stats
                
                st.success("âœ… å‰è™•ç†å®Œæˆï¼")
            
            if show_preprocessing and 'stats' in st.session_state:
                st.subheader("å‰è™•ç†çµ±è¨ˆçµæœ")
                stats = st.session_state.stats
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("è¨“ç·´é›†å‡å€¼", f"{stats['train_mean']:.4f}")
                    st.metric("è¨“ç·´é›†æ¨™å·®", f"{stats['train_std']:.4f}")
                with col2:
                    st.metric("æ¸¬è©¦é›†å‡å€¼", f"{stats['test_mean']:.4f}")
                    st.metric("æ¸¬è©¦é›†æ¨™å·®", f"{stats['test_std']:.4f}")
                with col3:
                    st.metric("è¨“ç·´é›†æœ€å°å€¼", f"{stats['train_min']:.4f}")
                    st.metric("è¨“ç·´é›†æœ€å¤§å€¼", f"{stats['train_max']:.4f}")
                
                # å¯è¦–åŒ–å‰å¾Œå°æ¯”
                if 'x_train_raw' in st.session_state:
                    fig, axes = plt.subplots(1, 3, figsize=(15, 4))
                    
                    sample_idx = st.slider("å°æ¯”æ¨£æœ¬ç´¢å¼•", 0, 59999, 0, key="compare_idx")
                    
                    # åŸå§‹åœ–åƒ
                    axes[0].imshow(st.session_state.x_train_raw[sample_idx], cmap='Greys')
                    axes[0].set_title("åŸå§‹åœ–åƒ")
                    axes[0].axis('off')
                    
                    # æ­£è¦åŒ–å¾Œ
                    axes[1].imshow(
                        MNISTPreprocessor.flatten(
                            MNISTPreprocessor.normalize(st.session_state.x_train_raw)
                        )[sample_idx].reshape(28, 28),
                        cmap='Greys'
                    )
                    axes[1].set_title("æ­£è¦åŒ–å¾Œ")
                    axes[1].axis('off')
                    
                    # å®Œå…¨å‰è™•ç†å¾Œ
                    axes[2].imshow(
                        st.session_state.x_train[sample_idx].reshape(28, 28),
                        cmap='Greys'
                    )
                    axes[2].set_title("å‰è™•ç†å¾Œ")
                    axes[2].axis('off')
                    
                    st.pyplot(fig)
    
    # ===== æ¨™ç±¤ 3: è¨“ç·´éç¨‹ =====
    with tab3:
        st.header("æ¨¡å‹è¨“ç·´")
        if 'x_train' not in st.session_state:
            st.warning("âš ï¸ è«‹å…ˆå®Œæˆæ•¸æ“šåŠ è¼‰å’Œå‰è™•ç†")
        else:
            if st.button("ğŸš‚ é–‹å§‹è¨“ç·´", key="train"):
                with st.spinner("è¨“ç·´ä¸­..."):
                    nn = MNISTNeuralNetwork(n1=n1, n2=n2, n3=n3, learning_rate=lr)
                    
                    st.write("æ¨¡å‹æ¶æ§‹:")
                    st.code(f"""
Layer 1: Dense(784) â†’ ReLU â†’ Dense({n1})
Layer 2: Dense({n1}) â†’ ReLU â†’ Dense({n2})
Layer 3: Dense({n2}) â†’ ReLU â†’ Dense({n3})
Layer 4: Dense({n3}) â†’ Softmax â†’ Dense(10)
                    """)
                    
                    history = nn.train(
                        st.session_state.x_train,
                        st.session_state.y_train,
                        batch_size=BATCH_SIZE,
                        epochs=epochs,
                        validation_split=VALIDATION_SPLIT
                    )
                    
                    st.session_state.model = nn
                    st.session_state.history = history
                
                st.success("âœ… è¨“ç·´å®Œæˆï¼")
            
            if show_training and 'history' in st.session_state:
                history = st.session_state.history
                
                # è¨“ç·´æ›²ç·š
                col1, col2 = st.columns(2)
                
                with col1:
                    fig, ax = plt.subplots(figsize=(10, 5))
                    ax.plot(history.history['loss'], label='è¨“ç·´ Loss', linewidth=2)
                    ax.plot(history.history['val_loss'], label='é©—è­‰ Loss', linewidth=2)
                    ax.set_xlabel('Epoch')
                    ax.set_ylabel('Loss')
                    ax.set_title('æå¤±å‡½æ•¸è®ŠåŒ–')
                    ax.legend()
                    ax.grid(True, alpha=0.3)
                    st.pyplot(fig)
                
                with col2:
                    fig, ax = plt.subplots(figsize=(10, 5))
                    ax.plot(history.history['accuracy'], label='è¨“ç·´ç²¾åº¦', linewidth=2)
                    ax.plot(history.history['val_accuracy'], label='é©—è­‰ç²¾åº¦', linewidth=2)
                    ax.set_xlabel('Epoch')
                    ax.set_ylabel('Accuracy')
                    ax.set_title('æº–ç¢ºç‡è®ŠåŒ–')
                    ax.legend()
                    ax.grid(True, alpha=0.3)
                    st.pyplot(fig)
    
    # ===== æ¨™ç±¤ 4: æ¨¡å‹è©•ä¼° =====
    with tab4:
        st.header("æ¨¡å‹è©•ä¼°")
        if 'model' not in st.session_state:
            st.warning("âš ï¸ è«‹å…ˆè¨“ç·´æ¨¡å‹")
        else:
            if st.button("ğŸ“Š è©•ä¼°æ¨¡å‹", key="evaluate"):
                with st.spinner("è©•ä¼°ä¸­..."):
                    loss, acc = st.session_state.model.evaluate(
                        st.session_state.x_test,
                        st.session_state.y_test
                    )
                    
                    y_pred = st.session_state.model.predict(st.session_state.x_test)
                    metrics = calculate_metrics(st.session_state.y_test, y_pred)
                    
                    st.session_state.metrics = metrics
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("æ¸¬è©¦æå¤±", f"{loss:.4f}")
                with col2:
                    st.metric("æ¸¬è©¦ç²¾åº¦", f"{acc*100:.2f}%")
            
            if show_metrics and 'metrics' in st.session_state:
                metrics = st.session_state.metrics
                
                # æ··æ·†çŸ©é™£
                st.subheader("æ··æ·†çŸ©é™£")
                fig, ax = plt.subplots(figsize=(10, 8))
                sns.heatmap(metrics['confusion_matrix'], annot=True, fmt='d', cmap='Blues', ax=ax, cbar_kws={'label': 'æ¨£æœ¬æ•¸'})
                ax.set_xlabel('é æ¸¬æ¨™ç±¤')
                ax.set_ylabel('çœŸå¯¦æ¨™ç±¤')
                st.pyplot(fig)
                
                # åˆ†é¡å ±å‘Š
                st.subheader("åˆ†é¡å ±å‘Š (é€é¡ç²¾åº¦)")
                report_df = st.session_state.metrics['classification_report']
                
                # è½‰æ›ç‚º DataFrame
                report_data = []
                for digit in range(10):
                    digit_str = str(digit)
                    if digit_str in report_df:
                        report_data.append({
                            'æ•¸å­—': digit,
                            'ç²¾åº¦': f"{report_df[digit_str]['precision']:.3f}",
                            'å¬å›ç‡': f"{report_df[digit_str]['recall']:.3f}",
                            'F1-åˆ†æ•¸': f"{report_df[digit_str]['f1-score']:.3f}",
                            'æ¨£æœ¬æ•¸': int(report_df[digit_str]['support'])
                        })
                
                st.dataframe(pd.DataFrame(report_data), use_container_width=True)
    
    # ===== æ¨™ç±¤ 5: å³æ™‚é æ¸¬ =====
    with tab5:
        st.header("å³æ™‚æ‰‹å¯«æ•¸å­—è¾¨è­˜")
        if 'model' not in st.session_state:
            st.warning("âš ï¸ è«‹å…ˆè¨“ç·´æ¨¡å‹")
        elif show_prediction:
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.subheader("å¾æ¸¬è©¦é›†é¸æ“‡")
                test_idx = st.slider("é¸æ“‡æ¸¬è©¦æ¨£æœ¬", 0, len(st.session_state.x_test)-1, 0)
                
                # é¡¯ç¤ºåœ–åƒ
                img_flat = st.session_state.x_test[test_idx]
                img_2d = img_flat.reshape(28, 28)
                
                fig, ax = plt.subplots(figsize=(5, 5))
                ax.imshow(img_2d, cmap='Greys')
                ax.set_title(f"æ¸¬è©¦æ¨£æœ¬ #{test_idx}")
                ax.axis('off')
                st.pyplot(fig)
                
                # é æ¸¬
                pred_prob = st.session_state.model.predict(img_flat.reshape(1, -1))[0]
                pred_class = np.argmax(pred_prob)
                
                col_left, col_right = st.columns(2)
                with col_left:
                    st.metric("é æ¸¬çµæœ", pred_class, delta=f"ä¿¡å¿ƒåº¦: {pred_prob[pred_class]*100:.1f}%")
                with col_right:
                    st.metric("çœŸå¯¦æ¨™ç±¤", int(np.argmax(st.session_state.y_test[test_idx])))
            
            with col2:
                st.subheader("é æ¸¬æ¦‚ç‡åˆ†å¸ƒ")
                
                pred_prob = st.session_state.model.predict(
                    st.session_state.x_test[test_idx].reshape(1, -1)
                )[0]
                
                fig, ax = plt.subplots(figsize=(8, 5))
                digits = list(range(10))
                colors = ['green' if i == np.argmax(pred_prob) else 'skyblue' for i in range(10)]
                ax.bar(digits, pred_prob, color=colors)
                ax.set_xlabel('æ•¸å­—')
                ax.set_ylabel('é æ¸¬æ¦‚ç‡')
                ax.set_title('å„æ•¸å­—çš„é æ¸¬æ¦‚ç‡')
                ax.set_xticks(digits)
                st.pyplot(fig)


# ===== åŸ·è¡Œ =====
if __name__ == "__main__":
    import pandas as pd
    main()
